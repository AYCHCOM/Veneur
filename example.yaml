---
api_hostname: https://app.datadoghq.com
metric_max_length: 4096
trace_max_length_bytes: 16384
flush_max_per_body: 25000
debug: true
enable_profiling: false
interval: "10s"
key: "farts"
# Numbers larger than 1 will enable the use of SO_REUSEPORT, make sure
# this is supported on your platform!
num_workers: 96
num_readers: 1
percentiles:
  - 0.5
  - 0.75
  - 0.99
aggregates:
 - "min"
 - "max"
 - "count"
read_buffer_size_bytes: 2097152
stats_address: "localhost:8125"
tags:
 - "foo:bar"
 - "baz:quz"
udp_address: "localhost:8126"
#http_address: "einhorn@0"
http_address: "localhost:8127"

### FORWARDING
# Use a static host for forwarding
forward_address: "http://veneur.example.com"

### TRACING
# The address on which we will listen for UDP trace data
trace_address: "127.0.0.1:8128"
# Use a static host to send datadog traces to
trace_api_address: "http://localhost:7777"

# If present, lightstep will be enabled as a tracing sink
# and this access token will be used
trace_lightstep_access_token: ""
trace_lightstep_collector_host: ""

sentry_dsn: ""

# If absent, defaults to the os.Hostname()!
hostname: foobar
# If true and hostname is "" or absent, don't add the host tag
omit_empty_hostname: false

# Include these if you want to archive data to S3
aws_access_key_id: ""
aws_secret_access_key: ""
aws_region: ""
aws_s3_bucket: ""

# Influde these if you want write to InfluxDB
influx_address: http://localhost:8086
influx_consistency: one
influx_db_name: mydb

# Listen address for statsd over TCP
tcp_address: ""

# TLS server private key and certificate for encryption (specify both)
# These are the key/certificate contents, not a file path
tls_key: ""
tls_certificate: ""

# Authority certificate: requires clients to be authenticated
tls_authority_certificate: ""

# Include this if you want to archive data to a local file (which should then be rotated/cleaned)
flush_file: ""
